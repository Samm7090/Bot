{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b398a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\samme\\git\\langchain_bot\\env311\\lib\\site-packages (from arxiv) (2.32.5)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samme\\git\\langchain_bot\\env311\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samme\\git\\langchain_bot\\env311\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samme\\git\\langchain_bot\\env311\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samme\\git\\langchain_bot\\env311\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n",
      "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6105 sha256=a3e269430fa8d25a8f20ec473f300d99ac947515ef258f56581affb9e1767ed0\n",
      "  Stored in directory: c:\\users\\samme\\appdata\\local\\pip\\cache\\wheels\\3b\\25\\2a\\105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ------------- -------------------------- 1/3 [feedparser]\n",
      "   ---------------------------------------- 3/3 [arxiv]\n",
      "\n",
      "Successfully installed arxiv-2.2.0 feedparser-6.0.12 sgmllib3k-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24d835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92568df",
   "metadata": {},
   "source": [
    "1st Retriver tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30113a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e72fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a30a695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd0f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7623cf67",
   "metadata": {},
   "source": [
    "2nd Reteriver tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf215fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samme\\AppData\\Local\\Temp\\ipykernel_21244\\1049955194.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.langchain.com/langsmith/home\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "embeddings=SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "vectordb=FAISS.from_documents(documents,embedding=embeddings)\n",
    "\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e47f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d05e9b8",
   "metadata": {},
   "source": [
    "To make retriver as CreateRetriverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066f929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriver_tool=create_retriever_tool(retriever,\"name=langsmith_search\",\"description=Search for the information about Langsmith. For any question about langsmith ask this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2055d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='name=langsmith_search', description='description=Search for the information about Langsmith. For any question about langsmith ask this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002E78A175800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002E78A175A80>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45546076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0c11f98",
   "metadata": {},
   "source": [
    "3rd Reteriver Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acab87dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arxiv Tool\n",
    "\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef457b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1b0836c",
   "metadata": {},
   "source": [
    "Let's combine this 3 tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba267a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki_tool,retriver_tool,arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11d8648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Samme\\\\Git\\\\Langchain_bot\\\\env311\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='name=langsmith_search', description='description=Search for the information about Langsmith. For any question about langsmith ask this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002E78A175800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002E78A175A80>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bd099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f666e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a6b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bd971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60f1fa67",
   "metadata": {},
   "source": [
    "Query from the specific tool and that is where we are using agents\n",
    "Agent will search the given query in all the tools and give the output whereever he will get the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6800720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92f6283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002E7FEF9CD60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002E7FEF9CD60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002E7FE343D50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002E7D956D510>, root_client=<openai.OpenAI object at 0x000002E7D90E1910>, root_async_client=<openai.AsyncOpenAI object at 0x000002E7D956D290>, model_name='mistralai/mistral-small-3.1-24b-instruct:free', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://openrouter.ai/api/v1'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'name=langsmith_search', 'description': 'description=Search for the information about Langsmith. For any question about langsmith ask this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Samme\\\\Git\\\\Langchain_bot\\\\env311\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='name=langsmith_search', description='description=Search for the information about Langsmith. For any question about langsmith ask this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000002E78A175800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000002E78A175A80>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002E78CC2B590>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55779274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangsmith is a platform designed to help developers and organizations manage, evaluate, and iterate on large language models (LLMs) and other AI models. It provides a suite of tools to streamline the process of working with AI, from training and fine-tuning models to deploying and monitoring them in production. Here are some key features and aspects of Langsmith:\n",
      "\n",
      "1. **Model Management**: Langsmith allows users to manage multiple models, track their versions, and maintain a centralized repository of AI assets. This is crucial for organizations that work with numerous models and need to keep track of their performance and updates.\n",
      "\n",
      "2. **Evaluation and Testing**: The platform offers tools for evaluating models on various metrics and datasets. This helps in understanding the strengths and weaknesses of different models and in making data-driven decisions for improvement.\n",
      "\n",
      "3. **Experiment Tracking**: Langsmith provides features to track experiments, including hyperparameters, training data, and results. This is essential for replicating experiments and understanding what works best.\n",
      "\n",
      "4. **Collaboration**: It facilitates collaboration among team members by providing shared workspaces, version control, and commenting features. This is particularly useful for teams working on complex AI projects.\n",
      "\n",
      "5. **Integration**: Langsmith can be integrated with other tools and frameworks commonly used in the AI/ML workflow, such as Jupyter notebooks, data pipelines, and deployment platforms.\n",
      "\n",
      "6. **Deployment and Monitoring**: The platform supports the deployment of models to various environments and provides monitoring tools to track their performance in real-time. This includes metrics like latency, throughput, and model accuracy.\n",
      "\n",
      "7. **Security and Compliance**: Langsmith emphasizes security and compliance, ensuring that models and data are handled according to industry standards and regulations.\n",
      "\n",
      "8. **Customization and Extensibility**: Users can customize the platform to fit their specific needs and extend its functionality through APIs and plugins.\n",
      "\n",
      "9. **User-Friendly Interface**: The platform is designed to be user-friendly, with intuitive interfaces for both technical and non-technical users.\n",
      "\n",
      "10. **Cost Management**: It helps in managing the costs associated with training and running AI models by providing insights into resource usage and optimization suggestions.\n",
      "\n",
      "Langsmith is aimed at making the lifecycle of AI models more efficient, transparent, and collaborative, ultimately helping organizations to build better AI solutions faster.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about Langsmith',\n",
       " 'output': 'Langsmith is a platform designed to help developers and organizations manage, evaluate, and iterate on large language models (LLMs) and other AI models. It provides a suite of tools to streamline the process of working with AI, from training and fine-tuning models to deploying and monitoring them in production. Here are some key features and aspects of Langsmith:\\n\\n1. **Model Management**: Langsmith allows users to manage multiple models, track their versions, and maintain a centralized repository of AI assets. This is crucial for organizations that work with numerous models and need to keep track of their performance and updates.\\n\\n2. **Evaluation and Testing**: The platform offers tools for evaluating models on various metrics and datasets. This helps in understanding the strengths and weaknesses of different models and in making data-driven decisions for improvement.\\n\\n3. **Experiment Tracking**: Langsmith provides features to track experiments, including hyperparameters, training data, and results. This is essential for replicating experiments and understanding what works best.\\n\\n4. **Collaboration**: It facilitates collaboration among team members by providing shared workspaces, version control, and commenting features. This is particularly useful for teams working on complex AI projects.\\n\\n5. **Integration**: Langsmith can be integrated with other tools and frameworks commonly used in the AI/ML workflow, such as Jupyter notebooks, data pipelines, and deployment platforms.\\n\\n6. **Deployment and Monitoring**: The platform supports the deployment of models to various environments and provides monitoring tools to track their performance in real-time. This includes metrics like latency, throughput, and model accuracy.\\n\\n7. **Security and Compliance**: Langsmith emphasizes security and compliance, ensuring that models and data are handled according to industry standards and regulations.\\n\\n8. **Customization and Extensibility**: Users can customize the platform to fit their specific needs and extend its functionality through APIs and plugins.\\n\\n9. **User-Friendly Interface**: The platform is designed to be user-friendly, with intuitive interfaces for both technical and non-technical users.\\n\\n10. **Cost Management**: It helps in managing the costs associated with training and running AI models by providing insights into resource usage and optimization suggestions.\\n\\nLangsmith is aimed at making the lifecycle of AI models more efficient, transparent, and collaborative, ultimately helping organizations to build better AI solutions faster.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6a5310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mMachine Learning (ML) is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without using explicit instructions. Instead of being programmed with exact rules, machine learning models learn patterns from data and make decisions or predictions based on that learning. Here are some key aspects of machine learning:\n",
      "\n",
      "### Types of Machine Learning\n",
      "\n",
      "1. **Supervised Learning**:\n",
      "   - **Definition**: The model is trained on a labeled dataset, meaning that each training example is paired with an output label.\n",
      "   - **Examples**: Classification (e.g., spam detection, image classification) and regression (e.g., predicting house prices, stock prices).\n",
      "   - **Common Algorithms**: Linear regression, logistic regression, decision trees, support vector machines (SVM), and neural networks.\n",
      "\n",
      "2. **Unsupervised Learning**:\n",
      "   - **Definition**: The model is given data without explicit instructions on what to do with it. The goal is to find hidden patterns or intrinsic structures in the data.\n",
      "   - **Examples**: Clustering (e.g., customer segmentation, image compression) and association (e.g., market basket analysis).\n",
      "   - **Common Algorithms**: K-means clustering, hierarchical clustering, and principal component analysis (PCA).\n",
      "\n",
      "3. **Semi-Supervised Learning**:\n",
      "   - **Definition**: The model is trained on a mixture of a small amount of labeled data and a large amount of unlabeled data.\n",
      "   - **Use Cases**: Helps in situations where obtaining labeled data is expensive or time-consuming.\n",
      "   - **Common Algorithms**: Self-training, multi-view training, and generative models.\n",
      "\n",
      "4. **Reinforcement Learning**:\n",
      "   - **Definition**: The model learns to make a sequence of decisions by interacting with an environment. The agent receives rewards or penalties based on its actions and aims to maximize cumulative reward.\n",
      "   - **Examples**: Game playing (e.g., AlphaGo), robotics, and autonomous driving.\n",
      "   - **Common Algorithms**: Q-learning, Deep Q-Networks (DQN), and policy gradient methods.\n",
      "\n",
      "### Key Concepts\n",
      "\n",
      "- **Model**: A mathematical representation of the relationships between inputs and outputs.\n",
      "- **Training**: The process of feeding data into the model to adjust its parameters and improve its performance.\n",
      "- **Validation**: The process of evaluating the model on a separate dataset to tune hyperparameters and prevent overfitting.\n",
      "- **Testing**: The process of evaluating the model's performance on an unseen dataset to assess its generalizability.\n",
      "- **Overfitting**: When a model performs well on training data but poorly on new, unseen data because it has learned the noise in the training data.\n",
      "- **Underfitting**: When a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and test data.\n",
      "- **Hyperparameters**: Parameters that are set before the training process begins, such as learning rate, number of neurons in a neural network, or the depth of a decision tree.\n",
      "- **Cross-Validation**: A technique to assess how the statistical analysis will generalize to an independent data set. It is often used to tune hyperparameters.\n",
      "\n",
      "### Applications of Machine Learning\n",
      "\n",
      "- **Healthcare**: Disease diagnosis, personalized medicine, and drug discovery.\n",
      "- **Finance**: Fraud detection, risk assessment, and algorithmic trading.\n",
      "- **Retail**: Recommendation systems, inventory management, and customer segmentation.\n",
      "- **Transportation**: Autonomous vehicles, route optimization, and predictive maintenance.\n",
      "- **Natural Language Processing (NLP)**: Sentiment analysis, machine translation, and chatbots.\n",
      "- **Computer Vision**: Image and video recognition, object detection, and facial recognition.\n",
      "\n",
      "### Tools and Frameworks\n",
      "\n",
      "- **Programming Languages**: Python, R, and Julia.\n",
      "- **Libraries and Frameworks**: TensorFlow, PyTorch, Scikit-learn, Keras, and XGBoost.\n",
      "- **Cloud Platforms**: AWS, Google Cloud, and Azure offer machine learning services and tools.\n",
      "\n",
      "Machine learning is a rapidly evolving field with extensive applications across various industries. As data becomes more abundant and computational power increases, the potential for machine learning to solve complex problems and drive innovation continues to grow.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about Machine Learning',\n",
       " 'output': \"Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without using explicit instructions. Instead of being programmed with exact rules, machine learning models learn patterns from data and make decisions or predictions based on that learning. Here are some key aspects of machine learning:\\n\\n### Types of Machine Learning\\n\\n1. **Supervised Learning**:\\n   - **Definition**: The model is trained on a labeled dataset, meaning that each training example is paired with an output label.\\n   - **Examples**: Classification (e.g., spam detection, image classification) and regression (e.g., predicting house prices, stock prices).\\n   - **Common Algorithms**: Linear regression, logistic regression, decision trees, support vector machines (SVM), and neural networks.\\n\\n2. **Unsupervised Learning**:\\n   - **Definition**: The model is given data without explicit instructions on what to do with it. The goal is to find hidden patterns or intrinsic structures in the data.\\n   - **Examples**: Clustering (e.g., customer segmentation, image compression) and association (e.g., market basket analysis).\\n   - **Common Algorithms**: K-means clustering, hierarchical clustering, and principal component analysis (PCA).\\n\\n3. **Semi-Supervised Learning**:\\n   - **Definition**: The model is trained on a mixture of a small amount of labeled data and a large amount of unlabeled data.\\n   - **Use Cases**: Helps in situations where obtaining labeled data is expensive or time-consuming.\\n   - **Common Algorithms**: Self-training, multi-view training, and generative models.\\n\\n4. **Reinforcement Learning**:\\n   - **Definition**: The model learns to make a sequence of decisions by interacting with an environment. The agent receives rewards or penalties based on its actions and aims to maximize cumulative reward.\\n   - **Examples**: Game playing (e.g., AlphaGo), robotics, and autonomous driving.\\n   - **Common Algorithms**: Q-learning, Deep Q-Networks (DQN), and policy gradient methods.\\n\\n### Key Concepts\\n\\n- **Model**: A mathematical representation of the relationships between inputs and outputs.\\n- **Training**: The process of feeding data into the model to adjust its parameters and improve its performance.\\n- **Validation**: The process of evaluating the model on a separate dataset to tune hyperparameters and prevent overfitting.\\n- **Testing**: The process of evaluating the model's performance on an unseen dataset to assess its generalizability.\\n- **Overfitting**: When a model performs well on training data but poorly on new, unseen data because it has learned the noise in the training data.\\n- **Underfitting**: When a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and test data.\\n- **Hyperparameters**: Parameters that are set before the training process begins, such as learning rate, number of neurons in a neural network, or the depth of a decision tree.\\n- **Cross-Validation**: A technique to assess how the statistical analysis will generalize to an independent data set. It is often used to tune hyperparameters.\\n\\n### Applications of Machine Learning\\n\\n- **Healthcare**: Disease diagnosis, personalized medicine, and drug discovery.\\n- **Finance**: Fraud detection, risk assessment, and algorithmic trading.\\n- **Retail**: Recommendation systems, inventory management, and customer segmentation.\\n- **Transportation**: Autonomous vehicles, route optimization, and predictive maintenance.\\n- **Natural Language Processing (NLP)**: Sentiment analysis, machine translation, and chatbots.\\n- **Computer Vision**: Image and video recognition, object detection, and facial recognition.\\n\\n### Tools and Frameworks\\n\\n- **Programming Languages**: Python, R, and Julia.\\n- **Libraries and Frameworks**: TensorFlow, PyTorch, Scikit-learn, Keras, and XGBoost.\\n- **Cloud Platforms**: AWS, Google Cloud, and Azure offer machine learning services and tools.\\n\\nMachine learning is a rapidly evolving field with extensive applications across various industries. As data becomes more abundant and computational power increases, the potential for machine learning to solve complex problems and drive innovation continues to grow.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"tell me about Machine Learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2695b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe paper titled \"1605.08386\" is a preprint that was uploaded to the arXiv repository. The specific details of the paper can vary, but as of my knowledge cutoff in October 2023, I can provide a general approach to finding out about it.\n",
      "\n",
      "To determine the content of arXiv:1605.08386, you can follow these steps:\n",
      "\n",
      "1. **Visit arXiv.org**: Go to the arXiv website, which hosts a large collection of preprints in various fields, particularly in physics, mathematics, computer science, and other scientific disciplines.\n",
      "\n",
      "2. **Search for the Paper**: Use the search function on arXiv.org and enter the identifier \"1605.08386\". This should bring up the specific paper you are interested in.\n",
      "\n",
      "3. **Read the Abstract and Introduction**: The abstract and introduction sections of the paper will provide a summary of the research, its objectives, methods, and key findings.\n",
      "\n",
      "4. **Check the Authors and Affiliations**: This can give you context about the background and expertise of the researchers involved.\n",
      "\n",
      "5. **Review the References**: The references section can provide insights into the related work and the broader context of the research.\n",
      "\n",
      "Alternatively, if you provide more specific details or context about the paper, I can offer more targeted information or discuss the general type of research that might be covered in a paper with such an identifier.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': 'The paper titled \"1605.08386\" is a preprint that was uploaded to the arXiv repository. The specific details of the paper can vary, but as of my knowledge cutoff in October 2023, I can provide a general approach to finding out about it.\\n\\nTo determine the content of arXiv:1605.08386, you can follow these steps:\\n\\n1. **Visit arXiv.org**: Go to the arXiv website, which hosts a large collection of preprints in various fields, particularly in physics, mathematics, computer science, and other scientific disciplines.\\n\\n2. **Search for the Paper**: Use the search function on arXiv.org and enter the identifier \"1605.08386\". This should bring up the specific paper you are interested in.\\n\\n3. **Read the Abstract and Introduction**: The abstract and introduction sections of the paper will provide a summary of the research, its objectives, methods, and key findings.\\n\\n4. **Check the Authors and Affiliations**: This can give you context about the background and expertise of the researchers involved.\\n\\n5. **Review the References**: The references section can provide insights into the related work and the broader context of the research.\\n\\nAlternatively, if you provide more specific details or context about the paper, I can offer more targeted information or discuss the general type of research that might be covered in a paper with such an identifier.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd873512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9acdf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71816ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449189a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
